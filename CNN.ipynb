{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['single-prediction', 'cat-and-dog']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c29069ee7ac91622a84964977d54789618ec24ce"
      },
      "cell_type": "code",
      "source": "# from IPython.display import Image, display\n# display(Image('../input/cat-and-dog/training_set/training_set/dogs/dog.1005.jpg'))\n# display(Image('../input/single-prediction/cat_or_dog_2.jpg'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6742cca84e2b338752e7138707ab154dd39c89b9"
      },
      "cell_type": "code",
      "source": "#Initialising the CNN \nclassifier=Sequential()\n\n# Step 1 convolution \n\nclassifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n\n#Step 2 - Pooling \n\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\n#Step 3- Flattening\nclassifier.add(Flatten())\n# Step 4- Full connection\nclassifier.add(Dense(output_dim=128,activation='relu'))\nclassifier.add(Dense(output_dim=1,activation='sigmoid'))\n\n# compiling The CNN\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n  from ipykernel import kernelapp as app\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n  app.launch_new_instance()\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3db07b50258b7e78197142f95cb2292b92c52b33"
      },
      "cell_type": "code",
      "source": "# Part 2 - Fitting the CNN to the images\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/cat-and-dog/training_set/training_set/',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\ntest_set = test_datagen.flow_from_directory('../input/cat-and-dog/test_set/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 8005 images belonging to 2 classes.\nFound 2023 images belonging to 2 classes.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b6463f98eb07827b92e70e456a04ba5b269d8ec"
      },
      "cell_type": "code",
      "source": "classifier.fit_generator(training_set,\n                   samples_per_epoch=8000, #steps_per_epoch = 8000,\n                   nb_epoch=25,            #epochs = 10,\n                   validation_data=test_set,\n                   nb_val_samples=2000)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n  \"\"\"\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Epoch 1/25\n250/250 [==============================] - 227s 909ms/step - loss: 0.6426 - acc: 0.6352 - val_loss: 0.6410 - val_acc: 0.6199\nEpoch 2/25\n250/250 [==============================] - 223s 891ms/step - loss: 0.6073 - acc: 0.6748 - val_loss: 0.5968 - val_acc: 0.6870\nEpoch 3/25\n250/250 [==============================] - 224s 895ms/step - loss: 0.5854 - acc: 0.6913 - val_loss: 0.5817 - val_acc: 0.6961\nEpoch 4/25\n250/250 [==============================] - 224s 896ms/step - loss: 0.5663 - acc: 0.7057 - val_loss: 0.5678 - val_acc: 0.7170\nEpoch 5/25\n250/250 [==============================] - 224s 895ms/step - loss: 0.5559 - acc: 0.7112 - val_loss: 0.5560 - val_acc: 0.7227\nEpoch 6/25\n250/250 [==============================] - 224s 895ms/step - loss: 0.5415 - acc: 0.7210 - val_loss: 0.5511 - val_acc: 0.7225\nEpoch 7/25\n250/250 [==============================] - 224s 895ms/step - loss: 0.5353 - acc: 0.7217 - val_loss: 0.5781 - val_acc: 0.7128\nEpoch 8/25\n250/250 [==============================] - 224s 896ms/step - loss: 0.5336 - acc: 0.7237 - val_loss: 0.5529 - val_acc: 0.7183\nEpoch 9/25\n250/250 [==============================] - 225s 899ms/step - loss: 0.5156 - acc: 0.7354 - val_loss: 0.5624 - val_acc: 0.7246\nEpoch 10/25\n250/250 [==============================] - 224s 897ms/step - loss: 0.5172 - acc: 0.7271 - val_loss: 0.5337 - val_acc: 0.7335\nEpoch 11/25\n250/250 [==============================] - 224s 895ms/step - loss: 0.5085 - acc: 0.7396 - val_loss: 0.5610 - val_acc: 0.7229\nEpoch 12/25\n250/250 [==============================] - 223s 892ms/step - loss: 0.5160 - acc: 0.7380 - val_loss: 0.5337 - val_acc: 0.7342\nEpoch 13/25\n250/250 [==============================] - 223s 892ms/step - loss: 0.4980 - acc: 0.7451 - val_loss: 0.5207 - val_acc: 0.7536\nEpoch 14/25\n250/250 [==============================] - 224s 897ms/step - loss: 0.4933 - acc: 0.7554 - val_loss: 0.5643 - val_acc: 0.7069\nEpoch 15/25\n250/250 [==============================] - 223s 893ms/step - loss: 0.4876 - acc: 0.7563 - val_loss: 0.5280 - val_acc: 0.7464\nEpoch 16/25\n250/250 [==============================] - 223s 893ms/step - loss: 0.4875 - acc: 0.7644 - val_loss: 0.5435 - val_acc: 0.7203\nEpoch 17/25\n250/250 [==============================] - 223s 893ms/step - loss: 0.4843 - acc: 0.7608 - val_loss: 0.5205 - val_acc: 0.7394\nEpoch 18/25\n250/250 [==============================] - 226s 902ms/step - loss: 0.4778 - acc: 0.7687 - val_loss: 0.5354 - val_acc: 0.7334\nEpoch 19/25\n250/250 [==============================] - 226s 905ms/step - loss: 0.4760 - acc: 0.7731 - val_loss: 0.5213 - val_acc: 0.7424\nEpoch 20/25\n250/250 [==============================] - 226s 903ms/step - loss: 0.4726 - acc: 0.7714 - val_loss: 0.5259 - val_acc: 0.7365\nEpoch 21/25\n250/250 [==============================] - 227s 908ms/step - loss: 0.4729 - acc: 0.7704 - val_loss: 0.5210 - val_acc: 0.7532\nEpoch 22/25\n250/250 [==============================] - 227s 909ms/step - loss: 0.4723 - acc: 0.7721 - val_loss: 0.5270 - val_acc: 0.7484\nEpoch 23/25\n250/250 [==============================] - 226s 905ms/step - loss: 0.4686 - acc: 0.7763 - val_loss: 0.5185 - val_acc: 0.7607\nEpoch 24/25\n250/250 [==============================] - 227s 906ms/step - loss: 0.4670 - acc: 0.7730 - val_loss: 0.5475 - val_acc: 0.7379\nEpoch 25/25\n250/250 [==============================] - 227s 908ms/step - loss: 0.4698 - acc: 0.7735 - val_loss: 0.5277 - val_acc: 0.7569\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fc379f36ac8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a8455128f2e31569970b6671ac431c31f917006"
      },
      "cell_type": "code",
      "source": "classifier.save('cat-dog-model.h5')",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "290af09ad590996f60d764494b1eafb7348809a6"
      },
      "cell_type": "code",
      "source": "from keras.models import load_model\nnew_model = load_model('cat-dog-model.h5')\n\nimport numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('../input/single-prediction/cat_or_dog_2.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = new_model.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb88474f1c1f75ba3e4d2e9e1fda96fca3f844af"
      },
      "cell_type": "code",
      "source": "prediction",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "'cat'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80a0d2d06aefd689c342be7cea8fbfeaed5eac48"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}